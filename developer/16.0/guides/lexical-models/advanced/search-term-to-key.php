<?php
  require_once('includes/template.php');

  head([
    'title' => "Search term to key"
  ]);
?>

<h1 class="title"> Search term to key </h1>

<p> To look up words quickly, the <code>trie</code> model creates a <dfn>
search key </dfn> that takes the latest word (as determined by the <a
href="word-breaker">word breaker</a> and converts it into an internal form.
The purpose of this internal form is to make searching for a word work,
as expected,
regardless of things such as <strong>accents</strong>,
<strong>diacritics</strong>, <strong>letter case</strong>, and minor
<strong>spelling variations</strong>.
The internal form is called the <dfn>key</dfn>.  Typically, the key is always
in lowercase, and lacks all accents and diacritics. For example, the key
for ‚Äúna√Øve" is <codE>naive</code> and the key for ‚ÄúCanada‚Äù is
<code>canada</code>. </p>

<p> The form of the word that is stored is ‚Äúregularized‚Äù through the use of a
<dfn>key function</dfn>, which you can define in TypeScript code. </p>

<p> Note: this function runs both <strong>on every word when the wordlist is
compiled</strong> and <strong>on the input, whenever a suggestion is requested</strong>.
This way, whatever a user types is <em>matched</em> to something stored in the
lexical model, without the user having to type things in a specific way.
</p>

<p> The key function takes a string which is the raw search term, and returns a
new string, being the ‚Äúregularized‚Äù key. As an example, consider the <strong>default
key function</strong>; that is, the key function that is used if you do not
specify one: </p>

<pre><code class="lang-typescript">searchTermToKey: function (term: string): string {
  // Use this pattern to remove common diacritical marks (accents).
  // See: https://www.compart.com/en/unicode/block/U+0300
  const COMBINING_DIACRITICAL_MARKS = /[\u0300-\u036f]/g;

  // Lowercase each letter in the string INDIVIDUALLY.
  // Why individually? Some languages have context-sensitive lowercasing
  // rules (e.g., Greek), which we would like to avoid.
  // So we convert the string into an array of code points (Array.from(term)),
  // convert each individual code point to lowercase (.map(c => c.toLowerCase())),
  // and join the pieces back together again (.join(''))
  let lowercasedTerm = Array.from(term).map(c => c.toLowerCase()).join('');

  // Once it's lowercased, we convert it to NFKD normalization form
  // This does many things, such as:
  //
  //  - separating characters from their accents/diacritics
  //      e.g., "√Ø" -> "i" + "‚óåÃà"
  //  - converting lookalike characters to a canonical ("regular") form
  //      e.g., "Õæ" -> ";" (yes, those are two completely different characters!)
  //  - converting "compatible" characters to their canonical ("regular") form
  //      e.g., "ùî•ùî¢ùî©ùî©ùî¨" -> "hello"
  let normalizedTerm = lowercasedTerm.normalize('NFKD');

  // Now, using the pattern defined above, replace each accent and diacritic with the
  // empty string. This effectively removes all accents and diacritics!
  //
  // e.g.,  "i" + "‚óåÃà" -> "i"
  let termWithoutDiacritics = normalizedTerm.replace(COMBINING_DIACRITICAL_MARKS, '');

  // The resultant key is lowercased, and has no accents or diacritics.
  return termWithoutDiacritics;
},</code></pre>

<p> This should be sufficient for most Latin-based writing systems. However,
there are cases, such as with SENƒÜO≈¶EN, where some characters do not decompose
into a base letter and a diacritic. In this case, it is necessary to write
your own key function. </p>

<h2> Use in your model definition file </h2>

<p> To use this in your model definition file, provide a function as the
<code>searchTermToKey</code> property of the lexical model source:</p>

<pre><code class="lang-typescript">const source: LexicalModelSource = {
  format: 'trie-1.0',
  sources: ['wordlist.tsv'],
  searchTermToKey: function (wordform: string): string {
    // Your searchTermToKey function goes here!
    let key = wordform.toLowerCase();
    return key;
  },
  // other customizations go here:
};

export default source;</code></pre>

<h2> Suggested customizations </h2>

<ul>
  <li> For all writing systems, <strong> normalize into NFKD</strong> or
       <strong>NFKC</strong> form using <code>wordform = wordform.normalize('NFKD')</code>. </li>
  <li> For Latin-based scripts, <strong>lowercase</strong> the word, and
      <strong>remove diacritics</strong>. </li>
  <li> For scripts that use the U+200C zero-width joiner (ZWJ) and/or the U+200D zero-width
       non-joiner (ZWNJ) (e.g., Brahmic scripts),
      <strong>remove the ZWJ or ZWNJ</strong> from the <strong>end</strong> of the input with
      <code>wordform = wordform.replace(/[\u200C\u200D]+$/</code> </li>
</ul>

<hr>

<p> <a href="./">Return to ‚ÄúAdvanced Lexical Model Topics‚Äù</a> </p>
